{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Muiti_class_Classification_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uTRpK3gwOyRT",
        "fFKQYS-5LGDC",
        "DL2rHPvwzXUQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8994e97716544ecaba1be2b64689c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb280c6f6b204d70b4712e94a79d99b1",
              "IPY_MODEL_bc93a5083d22421c8308f52a06b458bc",
              "IPY_MODEL_d7f9ab51cb14481ba3ff71307e321b72"
            ],
            "layout": "IPY_MODEL_49b35cb0901a407ebd89ec9757af6871"
          }
        },
        "eb280c6f6b204d70b4712e94a79d99b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_628eab655d394c88bd05590ef5f51e98",
            "placeholder": "​",
            "style": "IPY_MODEL_a51b274620404fe99bd690f97079988a",
            "value": "Downloading: 100%"
          }
        },
        "bc93a5083d22421c8308f52a06b458bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fc5b315d12c4f3590a7d80b245424cf",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9d83495c1534e99b38acb383ecbf61c",
            "value": 231508
          }
        },
        "d7f9ab51cb14481ba3ff71307e321b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb2ffc740beb4341ba90a0489efa9ada",
            "placeholder": "​",
            "style": "IPY_MODEL_f930258c2ba64209b5171c4cb03cc8d2",
            "value": " 226k/226k [00:00&lt;00:00, 622kB/s]"
          }
        },
        "49b35cb0901a407ebd89ec9757af6871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628eab655d394c88bd05590ef5f51e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51b274620404fe99bd690f97079988a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fc5b315d12c4f3590a7d80b245424cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d83495c1534e99b38acb383ecbf61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb2ffc740beb4341ba90a0489efa9ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f930258c2ba64209b5171c4cb03cc8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d61e6803b91469d92b865fce49ed55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdfae73bc2c543d0841f359b0a791f75",
              "IPY_MODEL_15f0ae0e4d184c9d88e5bf2371a537cb",
              "IPY_MODEL_7aff4d549eee44a5a283dc943050c9cf"
            ],
            "layout": "IPY_MODEL_6761e2fb6de946f7b0917c2e4294fd30"
          }
        },
        "cdfae73bc2c543d0841f359b0a791f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d3b47fadf947edbfbe7ef3034fc93d",
            "placeholder": "​",
            "style": "IPY_MODEL_d81068da1f28469ca781c47e22e4734d",
            "value": "Downloading: 100%"
          }
        },
        "15f0ae0e4d184c9d88e5bf2371a537cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473435915f5741ea88ab9ee6adde96fb",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77edaa69c03a4adab9da85eaa76a3b62",
            "value": 28
          }
        },
        "7aff4d549eee44a5a283dc943050c9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9513489e93b422f8429189f6274a4a6",
            "placeholder": "​",
            "style": "IPY_MODEL_44c30aa354344dbea8176b97065a5ae8",
            "value": " 28.0/28.0 [00:00&lt;00:00, 824B/s]"
          }
        },
        "6761e2fb6de946f7b0917c2e4294fd30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d3b47fadf947edbfbe7ef3034fc93d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81068da1f28469ca781c47e22e4734d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "473435915f5741ea88ab9ee6adde96fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77edaa69c03a4adab9da85eaa76a3b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9513489e93b422f8429189f6274a4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44c30aa354344dbea8176b97065a5ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8e53c953fa4410fa4fe7408c3374367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66c4c718ecff4ec084b562689db2030d",
              "IPY_MODEL_7e53f02880344a078755506d6f49091a",
              "IPY_MODEL_22d611c59bc549fabb15a83dc04c5344"
            ],
            "layout": "IPY_MODEL_b01a3ee05daa44738d658fc8a5115837"
          }
        },
        "66c4c718ecff4ec084b562689db2030d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c0e57f77224c519d5dfd4a287c243e",
            "placeholder": "​",
            "style": "IPY_MODEL_2c8f60d817a145d8815eaa0ced245e35",
            "value": "Downloading: 100%"
          }
        },
        "7e53f02880344a078755506d6f49091a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e98793ad1f4853b7fd4774864eb47a",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ff6a8a2796242cc85d988743262aae7",
            "value": 570
          }
        },
        "22d611c59bc549fabb15a83dc04c5344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62645b88f75f4c9e9ecb451afa76db99",
            "placeholder": "​",
            "style": "IPY_MODEL_e98403f30fcb4b4d8023e60994bb39be",
            "value": " 570/570 [00:00&lt;00:00, 16.2kB/s]"
          }
        },
        "b01a3ee05daa44738d658fc8a5115837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c0e57f77224c519d5dfd4a287c243e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c8f60d817a145d8815eaa0ced245e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11e98793ad1f4853b7fd4774864eb47a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ff6a8a2796242cc85d988743262aae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62645b88f75f4c9e9ecb451afa76db99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98403f30fcb4b4d8023e60994bb39be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889e71e2e23a4dc58db018c0a0c02d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c444898a306548369d2709fdf72576c0",
              "IPY_MODEL_d77ca4943d5444db9e9c4c52d9eb2f03",
              "IPY_MODEL_31ea1fb24d9448d3b6f312f3286d4913"
            ],
            "layout": "IPY_MODEL_012672dc4d7246318b90970df09c847a"
          }
        },
        "c444898a306548369d2709fdf72576c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad9bc0493774f8cbcf20f5debde5ab8",
            "placeholder": "​",
            "style": "IPY_MODEL_8e39a0a3b1c64b07b496845085440b3e",
            "value": "Downloading: 100%"
          }
        },
        "d77ca4943d5444db9e9c4c52d9eb2f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e84dbeac5f94bc0b252d87dd9293d64",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd0896b7a69e423badefd582a671a0fe",
            "value": 440473133
          }
        },
        "31ea1fb24d9448d3b6f312f3286d4913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae84067afcbd4b81bb5d12fee43b7d2c",
            "placeholder": "​",
            "style": "IPY_MODEL_aa99311a1dfc402d82c5b8327b317bc4",
            "value": " 420M/420M [00:13&lt;00:00, 35.0MB/s]"
          }
        },
        "012672dc4d7246318b90970df09c847a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad9bc0493774f8cbcf20f5debde5ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e39a0a3b1c64b07b496845085440b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e84dbeac5f94bc0b252d87dd9293d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd0896b7a69e423badefd582a671a0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae84067afcbd4b81bb5d12fee43b7d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa99311a1dfc402d82c5b8327b317bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-class Classification (BERT with PyTorch)\n",
        "By Yiting Mao"
      ],
      "metadata": {
        "id": "H61etZz6Q77Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install kaggle\n",
        "!pip install 'fsspec>=0.3.3'"
      ],
      "metadata": {
        "id": "tdQd5KjbY9Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score, precision_score, classification_report, confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import dask.bag as db\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import jieba as jb\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import torch\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import scipy.cluster.hierarchy as hcluster\n",
        "import scipy\n",
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "_4bivHazXIIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001e9dd1-93ee-4cae-ba2c-14832b2b49cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup\n",
        "## 1.1 Training using the Colab GPU"
      ],
      "metadata": {
        "id": "bjBOvPS4WO-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnEHXXRRW5JW",
        "outputId": "b75f06ed-b996-4078-c7dd-eeaf9fca1f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load arXiv Dataset\n",
        "## 2.1. Download & Extract"
      ],
      "metadata": {
        "id": "fBNBPWfWZDU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "token = {\"username\":\"karinmao\",\"key\":\"0145306b9df944a40f90e51f15167f9c\"}\n",
        "with open('/content/kaggle.json','w') as file:\n",
        "  json.dump(token,file)"
      ],
      "metadata": {
        "id": "1xRc8u5l7D9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v /content\n",
        "!kaggle datasets download -d Cornell-University/arxiv\n",
        "!unzip -uq \"/content/datasets/Cornell-University/arxiv/arxiv.zip\" -d \"/content/datasets/Cornell-University/arxiv\""
      ],
      "metadata": {
        "id": "UOBqa2dh7GDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ca10de-a16c-4f6b-977e-7a796fbd0ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- path is now set to: /content\n",
            "Downloading arxiv.zip to /content/datasets/Cornell-University/arxiv\n",
            " 99% 1.04G/1.05G [00:19<00:00, 70.6MB/s]\n",
            "100% 1.05G/1.05G [00:19<00:00, 56.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "docs = db.read_text('/content/datasets/Cornell-University/arxiv/arxiv-metadata-oai-snapshot.json').map(json.loads)"
      ],
      "metadata": {
        "id": "0-G710QI7QXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define target year\n",
        "year = 2021\n",
        "\n",
        "# Submissions by datetime\n",
        "get_year = lambda x: x['versions'][-1]['created'].split(' ')[3]\n",
        "\n",
        "# get only necessary fields\n",
        "trim = lambda x: {'id': x['id'],\n",
        "                  'title': x['title'],\n",
        "                  'category':x['categories'].split(' '),\n",
        "                  'abstract':x['abstract'],\n",
        "                  'time':x['versions'][-1]['created'].split(' ')[3]}\n",
        "\n",
        "# filter for papers published on or after ????-01-01\n",
        "docs_df = (docs.filter(lambda x: int(get_year(x)) > (year-1))\n",
        "               .filter(lambda x: int(get_year(x)) < (year+1))\n",
        "               .map(trim)\n",
        "               .compute())\n",
        "\n",
        "# convert to pandas dataframe\n",
        "docs_df = pd.DataFrame(docs_df)\n",
        "\n",
        "# add main category: list\n",
        "docs_df['main_category'] = docs_df.category.apply(lambda x:[a.split('.')[0] for a in x][0].split())\n",
        "\n",
        "# add main category 2: not list\n",
        "docs_df['main_category2'] = docs_df.main_category.apply(lambda x: x[0])"
      ],
      "metadata": {
        "id": "nWGxOrXEe8cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAP8mSKr35Br",
        "outputId": "91ed5514-89b7-4c11-af28-eecc60e182bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 340 entries, 0 to 339\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   id              340 non-null    object\n",
            " 1   title           340 non-null    object\n",
            " 2   category        340 non-null    object\n",
            " 3   abstract        340 non-null    object\n",
            " 4   time            340 non-null    object\n",
            " 5   main_category   340 non-null    object\n",
            " 6   main_category2  340 non-null    object\n",
            "dtypes: object(7)\n",
            "memory usage: 18.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_df2 = docs_df[['title','abstract','main_category','main_category2','category','time']]\n",
        "\n",
        "# Report the number of papers\n",
        "print('Number of total papers in year {:}: {:,}\\n'.format(year, docs_df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "docs_df2.sample(10)"
      ],
      "metadata": {
        "id": "tkGF9-wOetAl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "4c473e6c-0db6-4049-8f2e-cade6cd43995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of total papers in year 1991: 340\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "13    Twisted Black p-Brane Solutions in String Theory   \n",
              "101                   Scattering at Planckian Energies   \n",
              "266  Abelian Landau--Ginzburg Orbifolds and Mirror ...   \n",
              "63   Some Correlation Functions of Minimal Supercon...   \n",
              "257  From polymers to quantum gravity: triple-scali...   \n",
              "155             Extra Observables in Gauged WZW Models   \n",
              "235                        Matrix models of 2d gravity   \n",
              "56               Topology Change in General Relativity   \n",
              "328                         The Fibonacci unimodal map   \n",
              "259      Topological Approach to Alice Electrodynamics   \n",
              "\n",
              "                                              abstract main_category  \\\n",
              "13     It has been shown that given a classical bac...      [hep-th]   \n",
              "101    We give a systematic analysis of forward sca...      [hep-th]   \n",
              "266    We construct a class of Heterotic String vac...      [hep-th]   \n",
              "63     We compute general three-point functions of ...      [hep-th]   \n",
              "257    Rectangular $N\\times M$ matrix models can be...      [hep-th]   \n",
              "155    It is known that Liouville theory can be rep...      [hep-th]   \n",
              "235    These are introductory lectures for a genera...      [hep-th]   \n",
              "56     A review is given of recent work on topology...      [hep-th]   \n",
              "328    This paper will study topological, geometric...        [math]   \n",
              "259    We analyze the unlocalized ``Cheshire charge...      [hep-th]   \n",
              "\n",
              "    main_category2   category  time  \n",
              "13          hep-th   [hep-th]  1991  \n",
              "101         hep-th   [hep-th]  1991  \n",
              "266         hep-th   [hep-th]  1991  \n",
              "63          hep-th   [hep-th]  1991  \n",
              "257         hep-th   [hep-th]  1991  \n",
              "155         hep-th   [hep-th]  1991  \n",
              "235         hep-th   [hep-th]  1991  \n",
              "56          hep-th   [hep-th]  1991  \n",
              "328           math  [math.DS]  1991  \n",
              "259         hep-th   [hep-th]  1991  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3a8ca59-c0ef-43b1-95cc-5c065ce8df9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>main_category</th>\n",
              "      <th>main_category2</th>\n",
              "      <th>category</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Twisted Black p-Brane Solutions in String Theory</td>\n",
              "      <td>It has been shown that given a classical bac...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Scattering at Planckian Energies</td>\n",
              "      <td>We give a systematic analysis of forward sca...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>Abelian Landau--Ginzburg Orbifolds and Mirror ...</td>\n",
              "      <td>We construct a class of Heterotic String vac...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Some Correlation Functions of Minimal Supercon...</td>\n",
              "      <td>We compute general three-point functions of ...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>From polymers to quantum gravity: triple-scali...</td>\n",
              "      <td>Rectangular $N\\times M$ matrix models can be...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Extra Observables in Gauged WZW Models</td>\n",
              "      <td>It is known that Liouville theory can be rep...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>Matrix models of 2d gravity</td>\n",
              "      <td>These are introductory lectures for a genera...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Topology Change in General Relativity</td>\n",
              "      <td>A review is given of recent work on topology...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>The Fibonacci unimodal map</td>\n",
              "      <td>This paper will study topological, geometric...</td>\n",
              "      <td>[math]</td>\n",
              "      <td>math</td>\n",
              "      <td>[math.DS]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>Topological Approach to Alice Electrodynamics</td>\n",
              "      <td>We analyze the unlocalized ``Cheshire charge...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3a8ca59-c0ef-43b1-95cc-5c065ce8df9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3a8ca59-c0ef-43b1-95cc-5c065ce8df9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3a8ca59-c0ef-43b1-95cc-5c065ce8df9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine tile and abstract into a new column\n",
        "docs_df2[\"Title+abstract\"] = docs_df2[\"title\"] + \" \" + docs_df2[\"abstract\"]\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "docs_df2.sample(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "lNO5UFYm6VyT",
        "outputId": "9928d678-bff0-4919-b362-9c8967e32a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "12             String Winding in a Black Hole Geometry   \n",
              "247  Special geometry, cubic polynomials and homoge...   \n",
              "25     Correlation functions in super Liouville theory   \n",
              "\n",
              "                                              abstract main_category  \\\n",
              "12     $U(1)$ zero modes in the $SL(2,R)_k/U(1)$ an...      [hep-th]   \n",
              "247    The existing classification of homogeneous q...      [hep-th]   \n",
              "25     We calculate three- and four-point functions...      [hep-th]   \n",
              "\n",
              "    main_category2  category  time  \\\n",
              "12          hep-th  [hep-th]  1991   \n",
              "247         hep-th  [hep-th]  1991   \n",
              "25          hep-th  [hep-th]  1991   \n",
              "\n",
              "                                        Title+abstract  \n",
              "12   String Winding in a Black Hole Geometry   $U(1...  \n",
              "247  Special geometry, cubic polynomials and homoge...  \n",
              "25   Correlation functions in super Liouville theor...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-953bf82d-0a54-4422-adcc-37c4f7a12867\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>main_category</th>\n",
              "      <th>main_category2</th>\n",
              "      <th>category</th>\n",
              "      <th>time</th>\n",
              "      <th>Title+abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>String Winding in a Black Hole Geometry</td>\n",
              "      <td>$U(1)$ zero modes in the $SL(2,R)_k/U(1)$ an...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "      <td>String Winding in a Black Hole Geometry   $U(1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>Special geometry, cubic polynomials and homoge...</td>\n",
              "      <td>The existing classification of homogeneous q...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "      <td>Special geometry, cubic polynomials and homoge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Correlation functions in super Liouville theory</td>\n",
              "      <td>We calculate three- and four-point functions...</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>1991</td>\n",
              "      <td>Correlation functions in super Liouville theor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-953bf82d-0a54-4422-adcc-37c4f7a12867')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-953bf82d-0a54-4422-adcc-37c4f7a12867 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-953bf82d-0a54-4422-adcc-37c4f7a12867');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'cat':docs_df2['main_category2'].value_counts().index, 'count': docs_df2['main_category2'].value_counts()}\n",
        "df_cat = pd.DataFrame(data=d).reset_index(drop=True)\n",
        "num_labels = len(df_cat)\n",
        "# plot samples - categories\n",
        "df_cat.plot('cat','count',kind='bar')\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.title('year = %s'%(year))"
      ],
      "metadata": {
        "id": "WMOFrH_3BD6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict = {'astro-ph': 9, 'cond-mat': 3, 'cs': 6, 'econ': 16, 'eess': 18, 'funct-an': 20, 'gr-qc': 11, 'hep-ex': 19, 'hep-lat': 15,\n",
        " 'hep-ph': 1,'hep-th': 4, 'math': 0, 'math-ph': 7, 'nlin': 10, 'nucl-ex': 12, 'nucl-th': 17, 'physics': 2, 'q-alg': 21,\n",
        " 'q-bio': 13, 'q-fin': 14, 'quant-ph': 5, 'stat': 8, 'alg-geom':22, 'chao-dyn': 23, 'dg-ga': 24, 'adap-org': 25, 'solv-int': 26}\n",
        "\n",
        "dict2 = {'astro-ph': 9, 'cond-mat': 3, 'cs': 6, 'econ': 16, 'eess': 18, 'gr-qc': 11, 'hep-ex': 19, 'hep-lat': 15,\n",
        " 'hep-ph': 1,'hep-th': 4, 'math': 0, 'math-ph': 7, 'nlin': 10, 'nucl-ex': 12, 'nucl-th': 17, 'physics': 2,\n",
        " 'q-bio': 13, 'q-fin': 14, 'quant-ph': 5, 'stat': 8}"
      ],
      "metadata": {
        "id": "Wiz_9vVz3aEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define two categories\n",
        "# cat1 = 'math'\n",
        "# cat2 = 'physics'\n",
        "\n",
        "# filter for papers in 'cat1' or 'cat2' area\n",
        "# docs_df3 = docs_df2[(docs_df2.main_category.apply(lambda x: cat1 in x )==True)|(docs_df2.main_category.apply(lambda x: cat2 in x )==True)]\n",
        "docs_df3 = docs_df2\n",
        "\n",
        "# Report the number of papers in 'cat1' or 'cat2' area\n",
        "#print('Number of papers in {:} or {:} area: {:,}\\n'.format(cat1, cat2, docs_df3.shape[0]))\n",
        "\n",
        "# function for removing punctuations in abstracts\n",
        "def remove_punctuation(line):\n",
        "    line = str(line)\n",
        "    if line.strip() == '':\n",
        "        return ''\n",
        "    rule = re.compile(\"[^0-9a-zA-Z\\s-]\")\n",
        "    line = rule.sub('', line).strip()\n",
        "    return line\n",
        "\n",
        "# define stopwords\n",
        "#stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "# remove punctuation\n",
        "docs_df3['clean_abstract'] = docs_df3['abstract'].apply(remove_punctuation)\n",
        "docs_df3['clean_title'] = docs_df3['title'].apply(remove_punctuation)\n",
        "\n",
        "# remove stopwords\n",
        "# docs_df3['cut'] = docs_df3['clean_review'].apply(lambda x: \" \".join([w for w in list(jb.cut(x)) if w not in stopwords]))\n",
        "\n",
        "#docs_df3['cut'] = docs_df3['clean_abstract']\n",
        "docs_df4 = docs_df3[['clean_abstract','main_category2','category']]\n",
        "docs_df4_addtitle = docs_df3[['clean_abstract','clean_title','main_category2','category']]\n",
        "docs_df4_addtitle['clean_title_abstract'] = docs_df3['clean_title'] + \" \" + docs_df2['clean_abstract']\n",
        "docs_df4_addtitle = docs_df4_addtitle[['clean_title_abstract','main_category2','category']]\n",
        "\n",
        "# get the number of papers\n",
        "num_paper = len(docs_df4)\n",
        "\n",
        "# cat tansfer to id\n",
        "docs_df4['cat_id'] = docs_df4['main_category2'].map(dict)\n",
        "docs_df4_addtitle['cat_id'] = docs_df4_addtitle['main_category2'].map(dict)\n",
        "\n",
        "# filter for papers in 20/21/22 area\n",
        "#docs_df4 = docs_df4.drop(docs_df4[(docs_df4['cat_id']==20)|(docs_df4['cat_id']==21)|(docs_df4['cat_id']==22)|(docs_df4['cat_id']==23)|(docs_df4['cat_id']==24)|(docs_df4['cat_id']==25)|(docs_df4['cat_id']==26)].index)\n",
        "docs_df4 = docs_df4[docs_df4['cat_id'].isin(range(20))]\n",
        "\n",
        "# docs_df4['cat_id'] = docs_df3['main_category2'].factorize()[0]\n",
        "# docs_df4_addtitle['cat_id'] = docs_df3['main_category2'].factorize()[0]\n",
        "# cat_id_df = docs_df4[['main_category2', 'cat_id']].drop_duplicates().sort_values('cat_id').reset_index(drop=True)\n",
        "# cat_to_id = dict(cat_id_df.values)\n",
        "# id_to_cat = dict(cat_id_df[['cat_id', 'main_category2']].values)"
      ],
      "metadata": {
        "id": "hTo3ttdU73m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 10 random rows from the data version4.0 (abstract)\n",
        "docs_df4.sample(10)"
      ],
      "metadata": {
        "id": "qmFfdtfR_p9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "57200763-8095-4938-efb1-e0c8307c36dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        clean_abstract main_category2  \\\n",
              "65   We develop a kappa-symmetry calculus for the d...         hep-th   \n",
              "243  We ask whether the recently discovered superst...         hep-th   \n",
              "66   We exhibit a novel solution of the strong CP p...         hep-th   \n",
              "85   We use the Virasoro master equation to study t...         hep-th   \n",
              "153  Chern-Simons Theory with gauge group SUN is an...         hep-th   \n",
              "27   Factorization of the N-point amplitudes in two...         hep-th   \n",
              "86   It is argued that the effective string of what...         hep-th   \n",
              "283  The space of all solutions to the string equat...         hep-th   \n",
              "39   The c1 string in the Liouville field theory ap...         hep-th   \n",
              "164  The q--deformation Uq h4 of the harmonic oscil...         hep-th   \n",
              "\n",
              "              category  cat_id  \n",
              "65            [hep-th]       4  \n",
              "243           [hep-th]       4  \n",
              "66            [hep-th]       4  \n",
              "85            [hep-th]       4  \n",
              "153           [hep-th]       4  \n",
              "27            [hep-th]       4  \n",
              "86            [hep-th]       4  \n",
              "283           [hep-th]       4  \n",
              "39            [hep-th]       4  \n",
              "164  [hep-th, math.QA]       4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-963a2a1c-39f0-47aa-84b0-3e0b11563829\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_abstract</th>\n",
              "      <th>main_category2</th>\n",
              "      <th>category</th>\n",
              "      <th>cat_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>We develop a kappa-symmetry calculus for the d...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>We ask whether the recently discovered superst...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>We exhibit a novel solution of the strong CP p...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>We use the Virasoro master equation to study t...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>Chern-Simons Theory with gauge group SUN is an...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Factorization of the N-point amplitudes in two...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>It is argued that the effective string of what...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>The space of all solutions to the string equat...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>The c1 string in the Liouville field theory ap...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>The q--deformation Uq h4 of the harmonic oscil...</td>\n",
              "      <td>hep-th</td>\n",
              "      <td>[hep-th, math.QA]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-963a2a1c-39f0-47aa-84b0-3e0b11563829')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-963a2a1c-39f0-47aa-84b0-3e0b11563829 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-963a2a1c-39f0-47aa-84b0-3e0b11563829');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the lists of abstarcts / (title+abstarcts) and labels\n",
        "abstracts = docs_df4.clean_abstract.values\n",
        "#title_abstracts = docs_df4_addtitle.title + abstract.values\n",
        "labels = docs_df4.cat_id.values"
      ],
      "metadata": {
        "id": "Z867RMGnAnJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tokenization\n",
        "## 3.1 BERT Tokenizer"
      ],
      "metadata": {
        "id": "UfzCTAalA-mY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BERT tokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "d3rsS-K7BKWG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "e8994e97716544ecaba1be2b64689c99",
            "eb280c6f6b204d70b4712e94a79d99b1",
            "bc93a5083d22421c8308f52a06b458bc",
            "d7f9ab51cb14481ba3ff71307e321b72",
            "49b35cb0901a407ebd89ec9757af6871",
            "628eab655d394c88bd05590ef5f51e98",
            "a51b274620404fe99bd690f97079988a",
            "6fc5b315d12c4f3590a7d80b245424cf",
            "d9d83495c1534e99b38acb383ecbf61c",
            "bb2ffc740beb4341ba90a0489efa9ada",
            "f930258c2ba64209b5171c4cb03cc8d2",
            "8d61e6803b91469d92b865fce49ed55b",
            "cdfae73bc2c543d0841f359b0a791f75",
            "15f0ae0e4d184c9d88e5bf2371a537cb",
            "7aff4d549eee44a5a283dc943050c9cf",
            "6761e2fb6de946f7b0917c2e4294fd30",
            "99d3b47fadf947edbfbe7ef3034fc93d",
            "d81068da1f28469ca781c47e22e4734d",
            "473435915f5741ea88ab9ee6adde96fb",
            "77edaa69c03a4adab9da85eaa76a3b62",
            "a9513489e93b422f8429189f6274a4a6",
            "44c30aa354344dbea8176b97065a5ae8",
            "a8e53c953fa4410fa4fe7408c3374367",
            "66c4c718ecff4ec084b562689db2030d",
            "7e53f02880344a078755506d6f49091a",
            "22d611c59bc549fabb15a83dc04c5344",
            "b01a3ee05daa44738d658fc8a5115837",
            "65c0e57f77224c519d5dfd4a287c243e",
            "2c8f60d817a145d8815eaa0ced245e35",
            "11e98793ad1f4853b7fd4774864eb47a",
            "1ff6a8a2796242cc85d988743262aae7",
            "62645b88f75f4c9e9ecb451afa76db99",
            "e98403f30fcb4b4d8023e60994bb39be"
          ]
        },
        "outputId": "37ac4845-0377-4b02-8259-ac659eb31cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8994e97716544ecaba1be2b64689c99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d61e6803b91469d92b865fce49ed55b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8e53c953fa4410fa4fe7408c3374367"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the tokenizer to one abstract just to see the output\n",
        "# Print the original sentence.\n",
        "print(' Original: ', abstracts[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(abstracts[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(abstracts[0])))"
      ],
      "metadata": {
        "id": "Uq3ITvbCBakb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae40ff2-414c-40c2-8516-cb36884dca12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  We revisit the classical population genetics model of a population evolving\n",
            "under multiplicative selection mutation and drift The number of beneficial\n",
            "alleles in a multi-locus system can be considered a trait under exponential\n",
            "selection Equations of motion are derived for the cumulants of the trait\n",
            "distribution in the diffusion limit and under the assumption of linkage\n",
            "equilibrium Because of the additive nature of cumulants this reduces to the\n",
            "problem of determining equations of motion for the expected allele distribution\n",
            "cumulants at each locus The cumulant equations form an infinite dimensional\n",
            "linear system and in an authored appendix Adam Prugel-Bennett provides a closed\n",
            "form expression for these equations We derive approximate solutions which are\n",
            "shown to describe the dynamics well for a broad range of parameters In\n",
            "particular we introduce two approximate analytical solutions 1 Perturbation\n",
            "theory is used to solve the dynamics for weak selection and arbitrary mutation\n",
            "rate The resulting expansion for the systems eigenvalues reduces to the known\n",
            "diffusion theory results for the limiting cases with either mutation or\n",
            "selection absent 2 For low mutation rates we observe a separation of\n",
            "time-scales between the slowest mode and the rest which allows us to develop an\n",
            "approximate analytical solution for the dominant slow mode The solution is\n",
            "consistent with the perturbation theory result and provides a good\n",
            "approximation for much stronger selection intensities\n",
            "Tokenized:  ['we', 'rev', '##isi', '##t', 'the', 'classical', 'population', 'genetics', 'model', 'of', 'a', 'population', 'evolving', 'under', 'multi', '##pl', '##icative', 'selection', 'mutation', 'and', 'drift', 'the', 'number', 'of', 'beneficial', 'all', '##eles', 'in', 'a', 'multi', '-', 'locus', 'system', 'can', 'be', 'considered', 'a', 'trait', 'under', 'exponential', 'selection', 'equations', 'of', 'motion', 'are', 'derived', 'for', 'the', 'cum', '##ula', '##nts', 'of', 'the', 'trait', 'distribution', 'in', 'the', 'diffusion', 'limit', 'and', 'under', 'the', 'assumption', 'of', 'link', '##age', 'equilibrium', 'because', 'of', 'the', 'additive', 'nature', 'of', 'cum', '##ula', '##nts', 'this', 'reduces', 'to', 'the', 'problem', 'of', 'determining', 'equations', 'of', 'motion', 'for', 'the', 'expected', 'all', '##ele', 'distribution', 'cum', '##ula', '##nts', 'at', 'each', 'locus', 'the', 'cum', '##ula', '##nt', 'equations', 'form', 'an', 'infinite', 'dimensional', 'linear', 'system', 'and', 'in', 'an', 'authored', 'appendix', 'adam', 'pr', '##uge', '##l', '-', 'bennett', 'provides', 'a', 'closed', 'form', 'expression', 'for', 'these', 'equations', 'we', 'derive', 'approximate', 'solutions', 'which', 'are', 'shown', 'to', 'describe', 'the', 'dynamics', 'well', 'for', 'a', 'broad', 'range', 'of', 'parameters', 'in', 'particular', 'we', 'introduce', 'two', 'approximate', 'analytical', 'solutions', '1', 'per', '##tur', '##bation', 'theory', 'is', 'used', 'to', 'solve', 'the', 'dynamics', 'for', 'weak', 'selection', 'and', 'arbitrary', 'mutation', 'rate', 'the', 'resulting', 'expansion', 'for', 'the', 'systems', 'e', '##igen', '##val', '##ues', 'reduces', 'to', 'the', 'known', 'diffusion', 'theory', 'results', 'for', 'the', 'limiting', 'cases', 'with', 'either', 'mutation', 'or', 'selection', 'absent', '2', 'for', 'low', 'mutation', 'rates', 'we', 'observe', 'a', 'separation', 'of', 'time', '-', 'scales', 'between', 'the', 'slow', '##est', 'mode', 'and', 'the', 'rest', 'which', 'allows', 'us', 'to', 'develop', 'an', 'approximate', 'analytical', 'solution', 'for', 'the', 'dominant', 'slow', 'mode', 'the', 'solution', 'is', 'consistent', 'with', 'the', 'per', '##tur', '##bation', 'theory', 'result', 'and', 'provides', 'a', 'good', 'approximation', 'for', 'much', 'stronger', 'selection', 'int', '##ens', '##ities']\n",
            "Token IDs:  [2057, 7065, 17417, 2102, 1996, 4556, 2313, 14471, 2944, 1997, 1037, 2313, 20607, 2104, 4800, 24759, 25184, 4989, 16221, 1998, 11852, 1996, 2193, 1997, 15189, 2035, 26741, 1999, 1037, 4800, 1011, 25206, 2291, 2064, 2022, 2641, 1037, 18275, 2104, 27258, 4989, 11380, 1997, 4367, 2024, 5173, 2005, 1996, 13988, 7068, 7666, 1997, 1996, 18275, 4353, 1999, 1996, 19241, 5787, 1998, 2104, 1996, 11213, 1997, 4957, 4270, 14442, 2138, 1997, 1996, 29167, 3267, 1997, 13988, 7068, 7666, 2023, 13416, 2000, 1996, 3291, 1997, 12515, 11380, 1997, 4367, 2005, 1996, 3517, 2035, 12260, 4353, 13988, 7068, 7666, 2012, 2169, 25206, 1996, 13988, 7068, 3372, 11380, 2433, 2019, 10709, 8789, 7399, 2291, 1998, 1999, 2019, 8786, 22524, 4205, 10975, 22890, 2140, 1011, 8076, 3640, 1037, 2701, 2433, 3670, 2005, 2122, 11380, 2057, 18547, 15796, 7300, 2029, 2024, 3491, 2000, 6235, 1996, 10949, 2092, 2005, 1037, 5041, 2846, 1997, 11709, 1999, 3327, 2057, 8970, 2048, 15796, 17826, 7300, 1015, 2566, 20689, 23757, 3399, 2003, 2109, 2000, 9611, 1996, 10949, 2005, 5410, 4989, 1998, 15275, 16221, 3446, 1996, 4525, 4935, 2005, 1996, 3001, 1041, 29206, 10175, 15808, 13416, 2000, 1996, 2124, 19241, 3399, 3463, 2005, 1996, 14879, 3572, 2007, 2593, 16221, 2030, 4989, 9962, 1016, 2005, 2659, 16221, 6165, 2057, 11949, 1037, 8745, 1997, 2051, 1011, 9539, 2090, 1996, 4030, 4355, 5549, 1998, 1996, 2717, 2029, 4473, 2149, 2000, 4503, 2019, 15796, 17826, 5576, 2005, 1996, 7444, 4030, 5549, 1996, 5576, 2003, 8335, 2007, 1996, 2566, 20689, 23757, 3399, 2765, 1998, 3640, 1037, 2204, 20167, 2005, 2172, 6428, 4989, 20014, 6132, 6447]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Tokenize Dataset\n",
        "Required formatting for BERT:\n",
        "1. Add the special tokens [SEP] and [CLS] to the beginning and end of each sentence, respectively.\n",
        "2. All sentences should be padded and truncated to a single, constant length.\n",
        "3. Using the \"attention mask,\" explicitly distinguish actual tokens from padded tokens."
      ],
      "metadata": {
        "id": "5Kx4DORYEvRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "sum_len = 0\n",
        "\n",
        "# For every sample in abstracts...\n",
        "for sample in abstracts:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sample, add_special_tokens=True)\n",
        "\n",
        "    # Update sum of total sentence length\n",
        "    sum_len += len(input_ids)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max abstract length: ', max_len)\n",
        "print('Average abstract length: ', sum_len/len(abstracts))\n",
        "\n",
        "# # For every sample in title_abstracts...\n",
        "# for sample in title_abstracts:\n",
        "\n",
        "#     # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "#     input_ids = tokenizer.encode(sample, add_special_tokens=True)\n",
        "\n",
        "#     # Update sum of total sentence length\n",
        "#     sum_len += len(input_ids)\n",
        "\n",
        "#     # Update the maximum sentence length.\n",
        "#     max_len = max(max_len, len(input_ids))\n",
        "\n",
        "# print('Max abstract length: ', max_len)\n",
        "# print('Average abstract length: ', sum_len/len(abstracts))"
      ],
      "metadata": {
        "id": "TzAN-Y7fE7AA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6a4420-3f49-4baa-ad09-052cdb63340e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max abstract length:  349\n",
            "Average abstract length:  109.11176470588235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the abstracts and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sample in abstracts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sample,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', abstracts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "wut9k_fkGLvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd46318-4ec8-4726-ab72-593e2f9b7561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  We discuss properties of recursive schemas related to McCarthys 91\n",
            "function and to Takeuchis triple recursion Several theorems are proposed as\n",
            "interesting candidates for machine verification and some intriguing open\n",
            "questions are raised\n",
            "Token IDs: tensor([  101,  2057,  6848,  5144,  1997, 28667,  9236,  3512,  8040, 28433,\n",
            "         2015,  3141,  2000, 12584,  2015,  6205,  3853,  1998,  2000,  2202,\n",
            "        15217,  2015,  6420, 28667,  9236,  3258,  2195,  9872,  2015,  2024,\n",
            "         3818,  2004,  5875,  5347,  2005,  3698, 22616,  1998,  2070, 23824,\n",
            "         2330,  3980,  2024,  2992,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Training set ,Validation set and Testing set Split"
      ],
      "metadata": {
        "id": "eobFBnToKGoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 80-10-10 train-validation-test split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - (train_size + val_size)\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "trainval_dataset, test_dataset = random_split(dataset, [(train_size+val_size), test_size])\n",
        "train_dataset, val_dataset = random_split(trainval_dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} testing samples'.format(test_size))\n",
        "print(len(dataset),'total samples')"
      ],
      "metadata": {
        "id": "1ybpqZ1YKDQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(test_dataset,'test_dataset.pt')\n",
        "# torch.save(train_dataset,'train_dataset.pt')\n",
        "# torch.save(val_dataset,'val_dataset.pt')"
      ],
      "metadata": {
        "id": "r4jQsQHOirz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "JtVmiUv-OJob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train the Classification model\n",
        "## 4.1. BertForSequenceClassification"
      ],
      "metadata": {
        "id": "uTRpK3gwOyRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = num_labels, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "37Ln7H7yQVMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "889e71e2e23a4dc58db018c0a0c02d60",
            "c444898a306548369d2709fdf72576c0",
            "d77ca4943d5444db9e9c4c52d9eb2f03",
            "31ea1fb24d9448d3b6f312f3286d4913",
            "012672dc4d7246318b90970df09c847a",
            "7ad9bc0493774f8cbcf20f5debde5ab8",
            "8e39a0a3b1c64b07b496845085440b3e",
            "9e84dbeac5f94bc0b252d87dd9293d64",
            "fd0896b7a69e423badefd582a671a0fe",
            "ae84067afcbd4b81bb5d12fee43b7d2c",
            "aa99311a1dfc402d82c5b8327b317bc4"
          ]
        },
        "outputId": "86b13ae4-d2ee-4459-8753-d6d79cc7c42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "889e71e2e23a4dc58db018c0a0c02d60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "id": "TiWxz_0OQmo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0792a4cd-6c58-47e5-d584-47ee0cab94fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                          (20, 768)\n",
            "classifier.bias                                                (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Optimizer & Learning Rate\n",
        "Range:\n",
        "\n",
        "* **Batch size:** 16, 32  \n",
        "* **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "* **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "Chose:\n",
        "* **Batch size:** 16\n",
        "* **Learning rate:** 2e-5\n",
        "* **Epochs:** 3"
      ],
      "metadata": {
        "id": "fQKu_c0gQxi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# The 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "id": "GeqwfcF6QtQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe4e296-e5fa-49fa-d605-4a8154717378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "Z62syg51Rf0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. **Training**\n",
        "**Training:**\n",
        "- Unpack data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress"
      ],
      "metadata": {
        "id": "XanAgQF2RuPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "1NubE186Rr9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for formatting elapsed times as hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "Tzw_b93XSGC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4a1a15-51e2-42b4-dec3-9925a3bab391"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 3000 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch 3,000  of  10,450.    Elapsed: 0:33:14.\n",
            "  Batch 6,000  of  10,450.    Elapsed: 1:06:27.\n",
            "  Batch 9,000  of  10,450.    Elapsed: 1:39:40.\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 1:55:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:04:42\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch 3,000  of  10,450.    Elapsed: 0:33:10.\n",
            "  Batch 6,000  of  10,450.    Elapsed: 1:06:21.\n",
            "  Batch 9,000  of  10,450.    Elapsed: 1:39:31.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 1:55:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.47\n",
            "  Validation took: 0:04:42\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch 3,000  of  10,450.    Elapsed: 0:33:10.\n",
            "  Batch 6,000  of  10,450.    Elapsed: 1:06:21.\n",
            "  Batch 9,000  of  10,450.    Elapsed: 1:39:32.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 1:55:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:04:42\n",
            "\n",
            "Training complete!\n",
            "Total training took 6:00:56 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "FZbnUoD5PLt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "W2lkVVv2wY0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "cce64bc9-21fd-431a-e9e1-0c17cae65899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.64         0.51           0.82       1:55:42         0:04:42\n",
              "2               0.41         0.47           0.84       1:55:33         0:04:42\n",
              "3               0.29         0.51           0.84       1:55:34         0:04:42"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2e27289-d05f-4905-9e46-3c0eaeecfed4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.64</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.82</td>\n",
              "      <td>1:55:42</td>\n",
              "      <td>0:04:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1:55:33</td>\n",
              "      <td>0:04:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1:55:34</td>\n",
              "      <td>0:04:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2e27289-d05f-4905-9e46-3c0eaeecfed4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2e27289-d05f-4905-9e46-3c0eaeecfed4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2e27289-d05f-4905-9e46-3c0eaeecfed4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-rccg-CJwfy0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "838aef1a-bd96-421d-f02d-2fed41ebbe8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Test the Classification model"
      ],
      "metadata": {
        "id": "6bXfVv_Qw1aI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(test_size))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions, true_labels = [], []\n",
        "sum_acc = 0\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "  pred_label = logits.argmax(dim=1)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  pred_label = pred_label.to('cpu').numpy()\n",
        "  # print('true',label_ids)\n",
        "  # print('pre',pred_label)\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(pred_label.tolist())\n",
        "  true_labels.extend(label_ids.tolist())\n",
        "  # print('true',true_labels)\n",
        "  # print('pre',predictions)\n",
        "  sum_acc += flat_accuracy(logits, label_ids)\n",
        "  \n",
        "\n",
        "test_accuracy = sum_acc/len(test_dataloader)\n",
        "np.save('true_labels',true_labels,allow_pickle =False)\n",
        "np.save('predictions',predictions,allow_pickle =False)\n",
        "print('truelabel',true_labels)\n",
        "print('prediction',predictions)\n",
        "\n",
        "print(\"  Accuracy: {0:.2f}\".format(test_accuracy))\n",
        "print('DONE.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.any(np.isnan(predictions)))\n",
        "print(np.all(np.isfinite(predictions)))\n",
        "print(np.any(np.isnan(true_labels)))\n",
        "print(np.all(np.isfinite(true_labels)))"
      ],
      "metadata": {
        "id": "t6MLh6CkBaVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/M4R/BERT tutorial/true_labels_1991.npy', 'w') as f:\n",
        "    np.savetxt(f, true_labels)\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/M4R/BERT tutorial/predictions_1991.npy', 'w') as f:\n",
        "    np.savetxt(f, predictions)\n",
        "\n",
        "# read\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/M4R/BERT tutorial/predictions.npy', 'r') as f:\n",
        "#     a = np.loadtxt(f)"
      ],
      "metadata": {
        "id": "7DqYSnE8u7Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, predictions))"
      ],
      "metadata": {
        "id": "DTaQR7b-IYio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(22, 14), dpi=100)\n",
        "confusion_mat = confusion_matrix(true_labels, predictions, labels=None, sample_weight=None, normalize=None)\n",
        "cm = pd.DataFrame(confusion_mat,index=range(len(confusion_mat)),columns=range(len(confusion_mat)))\n",
        "sns.heatmap(cm.div(np.sum(cm,axis=1), axis='rows'),annot=True, fmt='.2%',cmap=\"RdPu\")\n",
        "plt.title(year,fontsize=30)\n",
        "plt.xlabel('PREDICTED',fontsize=30)\n",
        "plt.ylabel('ACTUAL',fontsize=30)\n"
      ],
      "metadata": {
        "id": "6pr1eVGZxCXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Save Fine-Tuned Model"
      ],
      "metadata": {
        "id": "fFKQYS-5LGDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "metadata": {
        "id": "cFGI0yxULzPW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "defb7a26-30a7-445e-f0ff-875b944d6059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1636b952d12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Save a trained model, configuration and tokenizer using `save_pretrained()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# They can then be reloaded using `from_pretrained()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'module'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;31m# Take care of distributed/parallel training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodel_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9LC_JHKML7uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c07c01b-7e0a-43b3-9365-e3e16df494e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "#!cp -r ./model_save/ \"/content/drive/MyDrive/Colab Notebooks/M4R/BERT tutorial\"\n",
        "!cp -r ./model_save/ \"/content/drive/MyDrive/Karin/\""
      ],
      "metadata": {
        "id": "pJPjeZYNMAAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Load Fine-Tuned Model"
      ],
      "metadata": {
        "id": "DL2rHPvwzXUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k2tM16dqM7C",
        "outputId": "1a1998da-7bf6-47ba-b832-734205b09c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_class = transformers.BertModel\n",
        "# tokenizer_class = transformers.BertTokenizer\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/M4R/BERT tutorial/model_save'\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "jzKx3SsAMC9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ef0f40-701f-4dc0-93ad-8746e5081a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import codecs, gc\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import KFold\n",
        "# from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
        "# from keras.metrics import top_k_categorical_accuracy\n",
        "# from keras.layers import *\n",
        "# from keras.callbacks import *\n",
        "# from keras.models import Model\n",
        "# import keras.backend as K\n",
        "# #from keras.optimizers import Adam\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        " \n",
        "# #读取训练集和测试集\n",
        "# # train_df=pd.read_csv('data/data_train.csv', sep='\\t', names=['id', 'type', 'contents', 'labels']).astype(str)\n",
        "# # test_df=pd.read_csv('data/data_test.csv', sep='\\t', names=['id', 'type', 'contents']).astype(str)\n",
        " \n",
        "# maxlen = 100  #设置序列长度为120，要保证序列长度不超过512\n",
        " \n",
        "# #预训练好的模型\n",
        "# config_path = 'chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_config.json'\n",
        "# checkpoint_path = 'chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_model.ckpt'\n",
        "# dict_path = 'chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/vocab.txt'\n",
        " \n",
        "# #将词表中的词编号转换为字典\n",
        "# token_dict = {}\n",
        "# with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
        "#     for line in reader:\n",
        "#         token = line.strip()\n",
        "#         token_dict[token] = len(token_dict)\n",
        " \n",
        "# #重写tokenizer        \n",
        "# class OurTokenizer(Tokenizer):\n",
        "#     def _tokenize(self, text):\n",
        "#         R = []\n",
        "#         for c in text:\n",
        "#             if c in self._token_dict:\n",
        "#                 R.append(c)\n",
        "#             elif self._is_space(c):\n",
        "#                 R.append('[unused1]')  # 用[unused1]来表示空格类字符\n",
        "#             else:\n",
        "#                 R.append('[UNK]')  # 不在列表的字符用[UNK]表示\n",
        "#         return R\n",
        "# tokenizer = OurTokenizer(token_dict)\n",
        " \n",
        "# #让每条文本的长度相同，用0填充\n",
        "# def seq_padding(X, padding=0):\n",
        "#     L = [len(x) for x in X]\n",
        "#     ML = max(L)\n",
        "#     return np.array([\n",
        "#         np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n",
        "#     ])\n",
        " \n",
        "# #data_generator只是一种为了节约内存的数据方式\n",
        "# class data_generator:\n",
        "#     def __init__(self, data, batch_size=32, shuffle=True):\n",
        "#         self.data = data\n",
        "#         self.batch_size = batch_size\n",
        "#         self.shuffle = shuffle\n",
        "#         self.steps = len(self.data) // self.batch_size\n",
        "#         if len(self.data) % self.batch_size != 0:\n",
        "#             self.steps += 1\n",
        " \n",
        "#     def __len__(self):\n",
        "#         return self.steps\n",
        " \n",
        "#     def __iter__(self):\n",
        "#         while True:\n",
        "#             idxs = list(range(len(self.data)))\n",
        " \n",
        "#             if self.shuffle:\n",
        "#                 np.random.shuffle(idxs)\n",
        " \n",
        "#             X1, X2, Y = [], [], []\n",
        "#             for i in idxs:\n",
        "#                 d = self.data[i]\n",
        "#                 text = d[0][:maxlen]\n",
        "#                 x1, x2 = tokenizer.encode(first=text)\n",
        "#                 y = d[1]\n",
        "#                 X1.append(x1)\n",
        "#                 X2.append(x2)\n",
        "#                 Y.append([y])\n",
        "#                 if len(X1) == self.batch_size or i == idxs[-1]:\n",
        "#                     X1 = seq_padding(X1)\n",
        "#                     X2 = seq_padding(X2)\n",
        "#                     Y = seq_padding(Y)\n",
        "#                     yield [X1, X2], Y[:, 0, :]\n",
        "#                     [X1, X2, Y] = [], [], []\n",
        " \n",
        "# #计算top-k正确率,当预测值的前k个值中存在目标类别即认为预测正确                 \n",
        "# def acc_top2(y_true, y_pred):\n",
        "#     return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        " \n",
        "# #bert模型设置\n",
        "# def build_bert(nclass):\n",
        "#     bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)  #加载预训练模型\n",
        " \n",
        "#     for l in bert_model.layers:\n",
        "#         l.trainable = True\n",
        " \n",
        "#     x1_in = Input(shape=(None,))\n",
        "#     x2_in = Input(shape=(None,))\n",
        " \n",
        "#     x = bert_model([x1_in, x2_in])\n",
        "#     x = Lambda(lambda x: x[:, 0])(x) # 取出[CLS]对应的向量用来做分类\n",
        "#     p = Dense(nclass, activation='softmax')(x)\n",
        " \n",
        "#     model = Model([x1_in, x2_in], p)\n",
        "#     model.compile(loss='categorical_crossentropy',\n",
        "#                   optimizer=Adam(1e-5),    #用足够小的学习率\n",
        "#                   metrics=['accuracy', acc_top2])\n",
        "#     print(model.summary())\n",
        "#     return model\n",
        " \n",
        "# #训练数据、测试数据和标签转化为模型输入格式\n",
        "# DATA_LIST = []\n",
        "# for data_row in train_df.iloc[:].itertuples():\n",
        "#     DATA_LIST.append((data_row.contents, to_categorical(data_row.labels, 3)))\n",
        "# DATA_LIST = np.array(DATA_LIST)\n",
        " \n",
        "# DATA_LIST_TEST = []\n",
        "# for data_row in test_df.iloc[:].itertuples():\n",
        "#     DATA_LIST_TEST.append((data_row.contents, to_categorical(0, 3)))\n",
        "# DATA_LIST_TEST = np.array(DATA_LIST_TEST)\n",
        " \n",
        "# #交叉验证训练和测试模型\n",
        "# def run_cv(nfold, data, data_labels, data_test):\n",
        "#     kf = KFold(n_splits=nfold, shuffle=True, random_state=520).split(data)\n",
        "#     train_model_pred = np.zeros((len(data), 3))\n",
        "#     test_model_pred = np.zeros((len(data_test), 3))\n",
        " \n",
        "#     for i, (train_fold, test_fold) in enumerate(kf):\n",
        "#         X_train, X_valid, = data[train_fold, :], data[test_fold, :]\n",
        " \n",
        "#         model = build_bert(3)\n",
        "#         early_stopping = EarlyStopping(monitor='val_acc', patience=3)   #早停法，防止过拟合\n",
        "#         plateau = ReduceLROnPlateau(monitor=\"val_acc\", verbose=1, mode='max', factor=0.5, patience=2) #当评价指标不在提升时，减少学习率\n",
        "#         checkpoint = ModelCheckpoint('./bert_dump/' + str(i) + '.hdf5', monitor='val_acc',verbose=2, save_best_only=True, mode='max', save_weights_only=True) #保存最好的模型\n",
        " \n",
        "#         train_D = data_generator(X_train, shuffle=True)\n",
        "#         valid_D = data_generator(X_valid, shuffle=True)\n",
        "#         test_D = data_generator(data_test, shuffle=False)\n",
        "#         #模型训练\n",
        "#         model.fit_generator(\n",
        "#             train_D.__iter__(),\n",
        "#             steps_per_epoch=len(train_D),\n",
        "#             epochs=5,\n",
        "#             validation_data=valid_D.__iter__(),\n",
        "#             validation_steps=len(valid_D),\n",
        "#             callbacks=[early_stopping, plateau, checkpoint],\n",
        "#         )\n",
        " \n",
        "#         # model.load_weights('./bert_dump/' + str(i) + '.hdf5')\n",
        " \n",
        "#         # return model\n",
        "#         train_model_pred[test_fold, :] = model.predict_generator(valid_D.__iter__(), steps=len(valid_D), verbose=1)\n",
        "#         test_model_pred += model.predict_generator(test_D.__iter__(), steps=len(test_D), verbose=1)\n",
        " \n",
        "#         del model\n",
        "#         gc.collect()   #清理内存\n",
        "#         K.clear_session()   #clear_session就是清除一个session\n",
        "#         # break\n",
        " \n",
        "#     return train_model_pred, test_model_pred\n",
        " \n",
        "# #n折交叉验证\n",
        "# train_model_pred, test_model_pred = run_cv(2, DATA_LIST, None, DATA_LIST_TEST)\n",
        " \n",
        "# test_pred = [np.argmax(x) for x in test_model_pred]\n",
        " \n",
        "# #将测试集预测结果写入文件\n",
        "# output=pd.DataFrame({'id':test_df.id,'sentiment':test_pred})\n",
        "# output.to_csv('data/results.csv', index=None)"
      ],
      "metadata": {
        "id": "vtTsFku162FS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}